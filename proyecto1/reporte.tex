\documentclass[12pt]{book}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[spanish]{babel}
\usepackage{fancyhdr}
\usepackage{listings, float, xcolor}
\usepackage{algorithm,algpseudocode, chngcntr}
\usepackage{graphicx, enumitem, geometry}
\usepackage{amsmath, amssymb, amsthm}
\usepackage{tcolorbox}

\geometry{margin=2.5cm}

\pagestyle{fancy}
\fancyhf{}

% Quitar mayúsculas automáticas
\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
\renewcommand{\sectionmark}[1]{\markright{#1}}
\renewcommand{\bibname}{Bibliografía} % redefine el título que pone thebibliography

% Encabezados
\lhead{LDP}
\rhead{\leftmark{}. \rightmark{}}
\cfoot{\thepage} % número centrado abajo
\renewcommand{\headrulewidth}{0.4pt}

% ----- Cambiar el título del índice -----
\addto\captionsspanish{%
  \renewcommand{\contentsname}{Índice} % cambia "Índice general" a "Índice"
}

% ----- Evitar mayúsculas en el encabezado del índice -----
\makeatletter
\renewcommand{\tableofcontents}{%
  \chapter*{\contentsname}% título "Índice"
  \markboth{\contentsname}{}% encabezado sin mayúsculas
  \@starttoc{toc}% genera el contenido real
}
\makeatother

\newcommand{\nt}[1]{\texttt{<#1>}}
\definecolor{azulin}{HTML}{130F87}
\definecolor{grisin}{HTML}{6D6C91}
\renewcommand{\lstlistingname}{Código}

% ----- Colores -----
\definecolor{keywordcolor1}{rgb}{0.5, 0.0, 0.5}   % Morado - palabras clave principales
\definecolor{keywordcolor2}{rgb}{0.0, 0.3, 0.7}   % Azul - tipos y construcciones
\definecolor{keywordcolor3}{rgb}{0.7, 0.2, 0.2}   % Rojo oscuro - funciones predefinidas
\definecolor{commentcolor}{rgb}{0.25, 0.5, 0.35}  % Verde comentarios
\definecolor{stringcolor}{rgb}{0.88, 0.68, 0.18}  % Mostaza strings
\definecolor{backgroundcolor}{rgb}{0.95, 0.95, 0.95} % Gris claro fondo

% ----- Estilo Haskell -----
\lstdefinestyle{haskellstyle}{
  language=Haskell,
  basicstyle=\ttfamily\footnotesize,
  keywordstyle=[1]\color{keywordcolor1}\bfseries, % if, then, else, let, in ...
  keywordstyle=[2]\color{keywordcolor2}\bfseries, % data, type, class ...
  keywordstyle=[3]\color{keywordcolor3},          % where, do, deriving ...
  commentstyle=\color{commentcolor}\itshape,
  stringstyle=\color{stringcolor},
  numbers=left,
  numberstyle=\tiny,
  stepnumber=1,
  numbersep=8pt,
  backgroundcolor=\color{backgroundcolor},
  tabsize=4,
  showspaces=false,
  showstringspaces=false,
  breaklines=true,
  frame=single,
  captionpos=b,
  morekeywords=[1]{if,then,else,let,in,case,of},           % grupo 1
  morekeywords=[2]{data,type,class,instance,where},        % grupo 2
  morekeywords=[3]{do,deriving,newtype,module,import},     % grupo 3
}

\begin{document}

\input{portada} % Importa el archivo portada.tex

\clearpage
\pagenumbering{arabic} % reinicia numeración con números arábigos
\setcounter{page}{1}   % empieza en la página 1

% Encabezado especial para TOC
\fancypagestyle{tocpage}{%
  \fancyhf{}
  \lhead{LDP}
  \rhead{Proyecto1. Reporte}
  \cfoot{\thepage}
  \renewcommand{\headrulewidth}{0.4pt}
}
\thispagestyle{tocpage}

\tableofcontents

\chapter{Introducción}

Como hemos visto en el curso Leguajes de Programación, al menos hasta la fecha de entrega del presente proyecto, en el desarrollo de un lenguaje de programación resulta fundamental comprender cómo se definen formalmente sus componentes y cómo estos se traducen a estructuras que una computadora puede interpretar y ejecutar.

\section{Motivación}
En el desarrollo de lenguajes de programación, Una de las motivaciones principales de este proyecto es acercarse al diseño de un lenguaje minimalista —en este caso, MINILISP— que permita practicar la construcción de gramáticas formales, analizadores léxicos y sintácticos, así como el modelado de árboles de sintaxis abstracta en un entorno académico.

\section{Objetivos}

El objetivo del proyecto es implementar un subconjunto del lenguaje Lisp con un conjunto reducido pero representativo de operaciones: expresiones aritméticas y booleanas, estructuras de control (if, cond), mecanismos de definición local (let, letrec, let*), funciones anónimas (lambda), listas y pares. Para ello, se diseña una gramática en notación BNF/EBNF, se define un conjunto de tokens para el análisis léxico y se construyen las estructuras de datos necesarias en Haskell para representar el árbol de sintaxis abstracta (ASA). De esta manera, se busca no solo capturar la semántica básica del lenguaje, sino también poner en práctica técnicas de diseño de compiladores a pequeña escala.

\section{Delimitación del Proyecto}
La delimitación del proyecto consiste en que MINILISP no pretende ser una implementación completa de Lisp, sino una versión simplificada con fines didácticos. Se restringe el conjunto de operaciones soportadas, se omite el manejo de macros y de entrada/salida, y se centra únicamente en el análisis sintáctico y la representación interna de programas. Con esto, se logra un balance entre la complejidad teórica y la viabilidad de implementación en el tiempo disponible.

\chapter{Sintaxis Concreta/Léxica}

El análisis léxico constituye la fase inicial en el proceso de interpretación de lenguajes de programación. Su objetivo es transformar una secuencia de caracteres sin estructura en una secuencia de tokens, que representan las unidades mínimas con significado léxico en nuestro lenguaje. Cada token encapsula información sobre el tipo de elemento reconocido y, cuando es relevante, su valor específico.

Herramienta Utilizada: Alex
Para la implementación del analizador léxico de nuestro miniLisp, seleccionamos Alex, el generador de analizadores léxicos estándar para Haskell. Esta elección se fundamenta en varias ventajas significativas:
+ Reducción de errores: Alex automatiza la generación de código robusto, minimizando errores comunes en implementaciones manuales.
+ Expresividad: Utiliza expresiones regulares extendidas para definir patrones léxicos de manera clara y concisa.
+ Integración con Haskell: Genera código Haskell nativo que se integra perfectamente con el resto de nuestro intérprete.
+ Eficiencia: Produce analizadores de alto rendimiento mediante algoritmos de coincidencia optimizados.

Estructura del Archivo Lexer.x
Lo primero que hacemos es importar las definiciones de tokens desde Tokens, que contiene el tipo de datos Token con todos los constructores necesarios. Después, definimos los patrones básicos que establecen los bloques fundamentales para construir patrones más complejos, promoviendo la reutilización y claridad. Estas líneas no son código Haskell, sino instrucciones para Alex. Le indican a Alex: "Cuando veas \$digit en las reglas, reemplázalo por 0-9".
Continuamos con los delimitadores estructurales compuestos por:
+ Patrón o expresión regular (lo que buscamos): La secuencia de caracteres que el lexer debe reconocer; en este caso nos referimos a “(“, “let”, “+”, etc. Es importante mencionar que los caracteres los podemos definir a gusto personal, pero para evitar crear un lenguaje confuso usaremos para cada token los ya reconocidos; es decir, para la suma “+”, para la resta “-”, etc.
+ Bloque de acción: Es el código Haskell que se ejecuta cuando se reconoce el patrón. Su propósito es generar el token correspondiente {...}.
+ Expresión lambda: Es todo lo que está en el bloque de acción, es decir, “\_ -> TokenPA”, donde \_ representa la cadena de texto que coincidió con el patrón, -> separa el parámetro del resultado, y TokenPA es el constructor del token que devolvemos.

Continuamos con las literales e identificadores: son los elementos fundamentales que representan los valores básicos y nombres en nuestro lenguaje. Son las “palabras” que contienen datos específicos en el programa. Para realizar el lexer tomamos como referencia lo visto en clase con el profesor (en su GitHub), además de usar la documentación oficial de Alex para desarrollar nuestro lexer.

\begin{lstlisting}[style=haskellstyle, caption={Estructura de Tokens}]
data Token
  = TokenVar String
  | TokenNum Int
  | TokenBool Bool
  | TokenAdd
  | TokenSub
  | TokenMul
  | TokenDiv
  | TokenAdd1
  | TokenSub1
  | TokenSqrt
  | TokenExpt
  | TokenNot
  | TokenEq
  | TokenLt
  | TokenGt
  | TokenNeq
  | TokenLeq
  | TokenGeq
  | TokenFirst 
  | TokenSecond
  | TokenHead
  | TokenTail
  | TokenLet
  | TokenLetRec
  | TokenLetStar
  | TokenIf0
  | TokenIf
  | TokenCond
  | TokenElse
  | TokenLambda
  | TokenApp
  | TokenLI
  | TokenLD
  | TokenComma
  | TokenPA
  | TokenPC
  deriving (Show, Eq)
\end{lstlisting}

Para ello usamos la dicumetación oficial de Alex.
The Alex Lexer Generator for Haskell
https://www.haskell.org/alex/
Programming in Haskell (Graham Hutton, 2nd Edition).
Sección sobre parsers y lexers.

\chapter{Sintaxis Libre de Contexto}

\newpage

\noindent
Definimos la Gramática para \large M\small INI\large L\small ISP \normalsize en \textbf{EBNF}:
\begin{tcolorbox}[colback=azulin!5!white, colframe=azulin!80, title=Gramática MINILISP]
\renewcommand{\arraystretch}{1.05}
\[
\begin{array}{rcl}
\nt{Expr} &::=& \nt{Var} \\
          &\mid& \nt{Num} \\
          &\mid& \nt{Bool} \\
          &\mid& \texttt{(+ \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(- \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(* \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(/ \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(add1 \nt{Expr})} \\
          &\mid& \texttt{(sub1 \nt{Expr})} \\
          &\mid& \texttt{(sqrt \nt{Expr})} \\
          &\mid& \texttt{(expt \nt{Expr})} \\
          &\mid& \texttt{(not \nt{Expr})} \\
          &\mid& \texttt{(= \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(<\: \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(>\: \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(<= \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(>= \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(!= \nt{Expr} \nt{Expr} \{\nt{Expr}\})} \\
          &\mid& \texttt{(\nt{Expr}, \nt{Expr})} \\
          &\mid& \texttt{(fst \nt{Expr})} \\
          &\mid& \texttt{(snd \nt{Expr})} \\
          &\mid& \texttt{(let ((\nt{Var} \nt{Expr}) \{\nt{Var} \nt{Expr}\}) \nt{Expr})} \\
          &\mid& \texttt{(letrec \nt{Var} \nt{Expr} \nt{Expr})} \\
          &\mid& \texttt{(let* ((\nt{Var} \nt{Expr}) \{\nt{Var} \nt{Expr}\}) \nt{Expr})} \\
          &\mid& \texttt{(if0 \nt{Expr} \nt{Expr} \nt{Expr})} \\
          &\mid& \texttt{(if \nt{Expr} \nt{Expr} \nt{Expr})} \\ 
          &\mid& \texttt{(lambda (\nt{Var} \{\nt{Var}\}) \nt{Expr})} \\
          &\mid& \texttt{(\nt{Expr} \nt{Expr})} \\
          &\mid& \texttt{\textbf{[}\nt{Expr} \{, \nt{Expr}\}\textbf{]}} \\
          &\mid& \texttt{(head \nt{Expr})} \\
          &\mid& \texttt{(tail \nt{Expr})} \\
          &\mid& \texttt{(cond [\nt{Expr} \nt{Expr}] \{[\nt{Expr} \nt{Expr}]\} [else \nt{Expr}])} \\
\\
\nt{Var} &::=& \textit{Identificador de variable} \\
\nt{Num} &::=& \textit{Constante entera} \\
\nt{Bool} &::=& \texttt{\#t} \mid \texttt{\#f}
\end{array}
\]
\end{tcolorbox}

Hacemos un abuso de notación para aclarar que el uso de '\textbf{[}' '\textbf{]}' no es para indicar opcionalidad de la notación de EBNF sino que son los símbolos que usamos para representar listas, también por eso están en negritas.

\newpage

\chapter{Sintaxis Abstracta}

\chapter{Azúcar sintáctica}
\section{Sintaxis Abstracta sin azúcar}
\section{Desugar}

\chapter{Semántica operacional}
\section{Paso pequeño}
\subsection{Evaluación perezosa}
\subsection{Evaluación ansiosa}

\chapter{Intérprete}

\chapter{Resultados}
\section{Funciones de prueba}
\subsection{Suma primeros $n$ números naturales}
\subsection{Factorial}
\subsection{Fibonacci}
\subsection{Función \texttt{map} para listas}
\subsection{Función \texttt{filter} para listas}

\chapter{Conclusiones}

\begin{thebibliography}{99}
  \bibitem{ref1} Autor. *Título del libro*. Editorial, Año.
  \bibitem{ref2} Autor. "Artículo". Revista, Año.
\end{thebibliography}


\end{document}
